{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4105e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.5\n"
     ]
    }
   ],
   "source": [
    "! pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0cb68d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.9.1-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.23.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (3.1.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.1.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.9.1\n"
     ]
    }
   ],
   "source": [
    "! pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5820fa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.10/site-packages (0.0.post1)\n"
     ]
    }
   ],
   "source": [
    "! pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3689e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import timedelta, datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8fa8271",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://dev_db_user:dev_db_pass@data_cleaning_db:5432/data_cleaning_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "512fac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * FROM cashflow_forecast.cleaned_aggregated_data WHERE AD_Client_ID = 1000298', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1acc14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ad_client_id</th>\n",
       "      <th>ad_org_id</th>\n",
       "      <th>dateinvoiced</th>\n",
       "      <th>c_bpartner_id</th>\n",
       "      <th>c_invoice_id</th>\n",
       "      <th>c_bpartner_location_id</th>\n",
       "      <th>paymentrule</th>\n",
       "      <th>grandtotal</th>\n",
       "      <th>duedate</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_late_paid</th>\n",
       "      <th>std_late_paid</th>\n",
       "      <th>max_unpaid</th>\n",
       "      <th>min_unpaid</th>\n",
       "      <th>avg_unpaid</th>\n",
       "      <th>std_unpaid</th>\n",
       "      <th>max_late_unpaid</th>\n",
       "      <th>min_late_unpaid</th>\n",
       "      <th>avg_late_unpaid</th>\n",
       "      <th>std_late_unpaid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3244082</td>\n",
       "      <td>1000298</td>\n",
       "      <td>1012210</td>\n",
       "      <td>2016-11-16</td>\n",
       "      <td>2107292</td>\n",
       "      <td>1704039</td>\n",
       "      <td>1458806</td>\n",
       "      <td>P</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2016-11-16</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3244083</td>\n",
       "      <td>1000298</td>\n",
       "      <td>1012210</td>\n",
       "      <td>2016-11-16</td>\n",
       "      <td>2107293</td>\n",
       "      <td>1704041</td>\n",
       "      <td>1458807</td>\n",
       "      <td>P</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2016-11-16</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3244165</td>\n",
       "      <td>1000298</td>\n",
       "      <td>1012210</td>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>2188183</td>\n",
       "      <td>1852334</td>\n",
       "      <td>1543354</td>\n",
       "      <td>P</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3244166</td>\n",
       "      <td>1000298</td>\n",
       "      <td>1012210</td>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>2188184</td>\n",
       "      <td>1852335</td>\n",
       "      <td>1543355</td>\n",
       "      <td>P</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3244167</td>\n",
       "      <td>1000298</td>\n",
       "      <td>1012210</td>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>2186956</td>\n",
       "      <td>1848802</td>\n",
       "      <td>1542038</td>\n",
       "      <td>P</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  ad_client_id  ad_org_id dateinvoiced  c_bpartner_id c_invoice_id  \\\n",
       "0  3244082       1000298    1012210   2016-11-16        2107292      1704039   \n",
       "1  3244083       1000298    1012210   2016-11-16        2107293      1704041   \n",
       "2  3244165       1000298    1012210   2017-04-06        2188183      1852334   \n",
       "3  3244166       1000298    1012210   2017-04-06        2188184      1852335   \n",
       "4  3244167       1000298    1012210   2017-04-03        2186956      1848802   \n",
       "\n",
       "   c_bpartner_location_id paymentrule  grandtotal    duedate  ...  \\\n",
       "0                 1458806           P        70.0 2016-11-16  ...   \n",
       "1                 1458807           P        30.0 2016-11-16  ...   \n",
       "2                 1543354           P        99.0 2017-04-06  ...   \n",
       "3                 1543355           P        90.0 2017-04-06  ...   \n",
       "4                 1542038           P       128.0 2017-04-03  ...   \n",
       "\n",
       "   avg_late_paid  std_late_paid max_unpaid min_unpaid  avg_unpaid  std_unpaid  \\\n",
       "0            NaN            NaN       70.0       70.0        70.0         NaN   \n",
       "1            NaN            NaN       30.0       30.0        30.0         NaN   \n",
       "2            NaN            NaN       99.0       99.0        99.0         0.0   \n",
       "3            NaN            NaN       90.0       90.0        90.0         NaN   \n",
       "4            NaN            NaN      128.0      128.0       128.0         NaN   \n",
       "\n",
       "   max_late_unpaid  min_late_unpaid  avg_late_unpaid  std_late_unpaid  \n",
       "0             70.0             70.0             70.0              NaN  \n",
       "1             30.0             30.0             30.0              NaN  \n",
       "2             99.0             99.0             99.0              0.0  \n",
       "3             90.0             90.0             90.0              NaN  \n",
       "4            128.0            128.0            128.0              NaN  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43826293",
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_features =['closed_late_invoices_no',\n",
    "                  'paid_late_percent',\n",
    "                  'paid_late_total',\n",
    "                  'paid_late_raport_percent',\n",
    "                  'avg_days_paid_late',\n",
    "                  'late_unpaid_invoices_no',\n",
    "                  'late_unpaid_invoices_percent',\n",
    "                  'unpaid_invoices_late_sum',\n",
    "                  'late_unpaid_invoices_sum_percent'\n",
    "               ] + [x + '_paid' for x in ['max', 'min', 'avg', 'std']] \\\n",
    "                 + [x + '_late_paid' for x in ['max', 'min', 'avg', 'std']] \\\n",
    "                 + [x + '_unpaid' for x in ['max', 'min', 'avg', 'std']] \\\n",
    "                 + [x + '_late_unpaid' for x in ['max', 'min', 'avg', 'std']]\n",
    "# numeric_features = [c for c in features if df[c].dtype!=object ]\n",
    "# categorical_features = [c for c in features if df[c].dtype==object]\n",
    "features = derived_features + ['late','dayslate','totalopenamt', 'paymentrule', 'tendertype']\n",
    "target = 'paid'\n",
    "\n",
    "numeric_features = [c for c in features if df[c].dtype!=object ]\n",
    "categorical_features = [c for c in features if df[c].dtype==object]\n",
    "\n",
    "target_reg = 'daystosettle'\n",
    "features_reg =[f for f in features if f not in [target, target_reg]]\n",
    "\n",
    "numeric_features_reg = [c for c in features_reg if df[c].dtype!=object]\n",
    "categorical_features_reg = [c for c in features_reg if df[c].dtype==object]\n",
    "cols = numeric_features_reg + categorical_features_reg +[target_reg, target, 'dateinvoiced']\n",
    "df[ ['c_invoice_id', 'ad_org_id', 'dateinvoiced', 'c_bpartner_id',\n",
    "       'c_bpartner_location_id'] + features + [target, target_reg]].drop_duplicates().to_csv('atribute_cbpartner.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f5a097b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8ea563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore',sparse = False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97658909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_clasificare(n_years, df, features, target):\n",
    "# pentru clasificare\n",
    "    X_train = df[df['dateinvoiced'] <= df['dateinvoiced'].max() + timedelta(days = -365*n_years)][features]\n",
    "    y_train = df[df['dateinvoiced'] <= df['dateinvoiced'].max() + timedelta(days = -365*n_years)][target]\n",
    "\n",
    "    X_test = df[(df['dateinvoiced'] > df['dateinvoiced'].max() + timedelta(days = -365*n_years)) &\n",
    "               (df['dateinvoiced'] <= df['dateinvoiced'].max() + timedelta(days = -365*(n_years-1)))][features]\n",
    "    y_test = df[(df['dateinvoiced'] > df['dateinvoiced'].max() + timedelta(days = -365*n_years)) &\n",
    "               (df['dateinvoiced'] <= df['dateinvoiced'].max() + timedelta(days = -365*(n_years-1)))][target]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72d34928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_regresie(n_years, df, features_reg, target_reg):\n",
    "\n",
    "\n",
    "    X_train_reg = df[(df.paid==1) & \n",
    "                     (df['dateinvoiced'] <= df['dateinvoiced'].max() + timedelta(days = -365*n_years))][features_reg]\n",
    "    Y_train_reg = df[(df.paid==1) & \n",
    "                     (df['dateinvoiced'] <= df['dateinvoiced'].max() + timedelta(days = -365*n_years))][target_reg]\n",
    "\n",
    "    X_test_reg = df[(df.paid==1) & (df['dateinvoiced'] > df['dateinvoiced'].max() + timedelta(days = -365*n_years)) &\n",
    "               (df['dateinvoiced'] <= df['dateinvoiced'].max() + timedelta(days = -365*(n_years-1)))][features_reg]\n",
    "\n",
    "    Y_test_reg = df[(df.paid==1) & (df['dateinvoiced'] > df['dateinvoiced'].max() + timedelta(days = -365*n_years)) &\n",
    "               (df['dateinvoiced'] <= df['dateinvoiced'].max() + timedelta(days = -365*(n_years-1)))][target_reg]\n",
    "    X_train_reg.fillna(value=X_train_reg.mean(), inplace=True)\n",
    "    Y_train_reg.fillna(value=Y_train_reg.mean(), inplace=True)\n",
    "    X_test_reg.fillna(value=X_test_reg.mean(), inplace=True)\n",
    "    Y_test_reg.fillna(value=Y_test_reg.mean(), inplace=True)\n",
    "    return X_train_reg, Y_train_reg, X_test_reg, Y_test_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ed7e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def antrenare_clasificare(df, numeric_features, categorical_features, target, n_years):\n",
    " \n",
    "    X_train, y_train, X_test, y_test = split_clasificare(n_years, df, numeric_features + categorical_features, target)\n",
    "    # la stringul 'classifier' adaugam '__' si sufixul reprezentat de parametrul\n",
    "    param_grid = [\n",
    "\n",
    "       {'classifier' : [RandomForestClassifier()],\n",
    "        'classifier__n_estimators' : [10,100,500],\n",
    "        'classifier__max_samples' : [0.1, 0.2, 0.3]},\n",
    "       # mai multe modele de incercat aici: logistic regression, XGBoost, SVM\n",
    "    ]\n",
    "\n",
    "    # bucla pentru tunarea si evaluarea clasificatorilor. returnam metrici pe care le putem colecta intr-un dataframe\n",
    "    lista_rezultate = []\n",
    "    lista_obiecte_grid_search = []\n",
    "\n",
    "    for clf_dict in param_grid:\n",
    "\n",
    "        # pasului de preprocesare ii adaugam clasificatorul curent; nu putem adauga decat un singur evaluator in\n",
    "        # pipeline, la sfarsit; de aceea am recurs la bucla\n",
    "        clsf = Pipeline(steps=[        \n",
    "                               ( 'column_transformer', ColumnTransformer(\n",
    "                            transformers=[\n",
    "                                ('num', numeric_transformer, \n",
    "                                 [list(X_train.columns.values).index(e) for e in numeric_features]),\n",
    "                                ('cat', categorical_transformer, \n",
    "                                  [list(X_train.columns.values).index(e) for e in categorical_features])],\n",
    "                               remainder='passthrough')                                         \n",
    "\n",
    "                           ),\n",
    "                              ('classifier', clf_dict['classifier'][0])])\n",
    "\n",
    "        grid = GridSearchCV(clsf, [clf_dict], cv=5, scoring='accuracy', verbose=0, n_jobs=-1)\n",
    "\n",
    "        # antrenare si fit\n",
    "        grid.fit(X_train, y_train)   \n",
    "\n",
    "        # predictie cu cea mai buna configurare in functie de scoringul ales - in cazul de mai sus accuracy\n",
    "        y_pred = grid.predict(X_test)\n",
    "\n",
    "        # curba roc\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "\n",
    "        # matricea de confuzie\n",
    "        cfmtrx = metrics.confusion_matrix(y_test,y_pred)\n",
    "\n",
    "        # culegem rezultatele in dictionare cu aceleasi chei - cel mai usor de transformat\n",
    "        lista_rezultate.append({\n",
    "            'classifierName': type(clf_dict['classifier'][0]),\n",
    "            'best_score':grid.best_score_,\n",
    "            'best_params':grid.best_params_,\n",
    "            'auc':metrics.roc_auc_score(y_test,y_pred),\n",
    "            'precision':metrics.precision_score(y_test,y_pred),\n",
    "            'recall':metrics.recall_score(y_test,y_pred),\n",
    "            'f1':metrics.f1_score(y_test,y_pred),\n",
    "            'FP':cfmtrx[0,1],\n",
    "            'FN':cfmtrx[1,0],\n",
    "            'TP':cfmtrx[1,1],\n",
    "            'TN':cfmtrx[0,0],\n",
    "            'grid_obj':grid\n",
    "\n",
    "        })\n",
    "        print('Done with {0}'.format(type(clf_dict['classifier'][0])))\n",
    "\n",
    "    df_result = pd.DataFrame(lista_rezultate)\n",
    "    df_result = df_result.sort_values(by ='best_score', ascending = False)\n",
    "    print(df_result.head())\n",
    "    # cel mai bun model\n",
    "    clsf = df_result.sort_values(by ='best_score', ascending = False).grid_obj[0].best_estimator_\n",
    "    # testarea: \n",
    "    clsf.fit(X_train,y_train)\n",
    "    y_pred = clsf.predict(X_test)\n",
    "    print(\"model score: %.3f\" % clsf.score(X_test, y_test))\n",
    "    c = confusion_matrix(y_test,y_pred)\n",
    "    \n",
    "    return clsf, df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad25e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def antrenare_regresie(df, numeric_features_reg,categorical_features_reg, target_reg, n_years ):\n",
    "    \n",
    "    cols = [c for c in df if c in numeric_features_reg + categorical_features_reg +[target_reg]]\n",
    "    features_reg = numeric_features_reg + categorical_features_reg\n",
    "    \n",
    "    X_train_reg, y_train_reg, X_test_reg, y_test_reg = split_regresie(n_years, df, features_reg, target_reg)\n",
    "\n",
    "    # lasso are un CV propriu. fapt pentru care standardizarea se va face acolo si o scoatem din preprocesare\n",
    "    numeric_transformer2 = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=0))])\n",
    "    \n",
    "    categorical_transformer2 = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore',sparse = False))])\n",
    "    \n",
    "    datatrsfm = Pipeline(steps=[        \n",
    "                           ( 'column_transformer', ColumnTransformer(\n",
    "                        transformers=[\n",
    "                            ('num', numeric_transformer2, \n",
    "                             [list(df[cols].columns.values).index(e) for e in numeric_features_reg]),\n",
    "                            ('cat', categorical_transformer2, \n",
    "                              [list(df[cols].columns.values).index(e) for e in categorical_features_reg])],\n",
    "                           remainder='passthrough'\n",
    "                           )                                         \n",
    "\n",
    "                       )])\n",
    "\n",
    "    lambda_values = 10**np.linspace(10,-3,100)*0.5\n",
    "    X_train_reg_trf = datatrsfm.fit_transform(X_train_reg)\n",
    "\n",
    "    lassocv = LassoCV(alphas = lambda_values, cv = 10, max_iter = 100000, normalize = True)\n",
    "\n",
    "    # antrenare si fit\n",
    "    lassocv.fit(X_train_reg_trf, y_train_reg)   \n",
    "\n",
    "    #pas 5\n",
    "    lambda_optim = lassocv.alpha_\n",
    "\n",
    "    # pas 6: reantrenare pe toate datele de antrenament\n",
    "    lasso = Lasso(max_iter = 100000, normalize = True)\n",
    "    lasso.set_params(alpha=lambda_optim)\n",
    "    lasso.fit(X_train_reg_trf, y_train_reg)\n",
    "\n",
    "    # pas 7 - raportatea erorii\n",
    "\n",
    "    pipeline_reg = Pipeline(steps=[        \n",
    "                       ( 'column_transformer', ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        ('num', numeric_transformer, \n",
    "                         [list(df[cols].columns.values).index(e) for e in numeric_features_reg]),\n",
    "                        ('cat', categorical_transformer, \n",
    "                          [list(df[cols].columns.values).index(e) for e in categorical_features_reg])],\n",
    "                       remainder='passthrough') ),\n",
    "                     ('lasso',lasso)   \n",
    "\n",
    "                   ])\n",
    "\n",
    "    pipeline_reg.fit(X_train_reg, y_train_reg)\n",
    "    y_hat_train_reg = pipeline_reg.predict(X_train_reg)\n",
    "    y_hat_test_reg = pipeline_reg.predict(X_test_reg)\n",
    "\n",
    "\n",
    "    cv_alpha_test_error = mean_squared_error(y_train_reg, \n",
    "                                             y_hat_train_reg)\n",
    "\n",
    "    print(\"MSE date test :\", cv_alpha_test_error)\n",
    "\n",
    "    # score(X, y[, sample_weight]) - coeficientul de determinare R^2 all predictiei.\n",
    "    print(\"R^2 pe date de anternament: {0}\".format(pipeline_reg.score(X_train_reg,y_train_reg)))\n",
    "    print(\"R^2 pe date de test: {0}\".format(pipeline_reg.score(X_test_reg,y_test_reg)))\n",
    "    return pipeline_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5072abc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_years:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1018: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "                                      classifierName  best_score  \\\n",
      "0  <class 'sklearn.ensemble._forest.RandomForestC...    0.989538   \n",
      "\n",
      "                                         best_params       auc  precision  \\\n",
      "0  {'classifier': RandomForestClassifier(max_samp...  0.818571   0.978424   \n",
      "\n",
      "     recall        f1   FP  FN     TP   TN  \\\n",
      "0  0.999938  0.989064  353   1  16008  620   \n",
      "\n",
      "                                            grid_obj  \n",
      "0  GridSearchCV(cv=5,\\n             estimator=Pip...  \n",
      "model score: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59/2840836754.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_train_reg.fillna(value=Y_train_reg.mean(), inplace=True)\n",
      "/tmp/ipykernel_59/2840836754.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_test_reg.fillna(value=Y_test_reg.mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE date test : 60.378115284490995\n",
      "R^2 pe date de anternament: 0.9265784484766998\n",
      "R^2 pe date de test: 0.9057771688781692\n",
      "n_years:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1018: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "                                      classifierName  best_score  \\\n",
      "0  <class 'sklearn.ensemble._forest.RandomForestC...    0.993515   \n",
      "\n",
      "                                         best_params       auc  precision  \\\n",
      "0  {'classifier': RandomForestClassifier(max_samp...  0.727778   0.996863   \n",
      "\n",
      "   recall        f1  FP  FN     TP  TN  \\\n",
      "0     1.0  0.998429  49   0  15573  41   \n",
      "\n",
      "                                            grid_obj  \n",
      "0  GridSearchCV(cv=5,\\n             estimator=Pip...  \n",
      "model score: 0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59/2840836754.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_train_reg.fillna(value=Y_train_reg.mean(), inplace=True)\n",
      "/tmp/ipykernel_59/2840836754.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_test_reg.fillna(value=Y_test_reg.mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE date test : 66.59787467792312\n",
      "R^2 pe date de anternament: 0.9265158471632446\n",
      "R^2 pe date de test: 0.9363922303919188\n",
      "n_years:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1018: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "                                      classifierName  best_score  \\\n",
      "0  <class 'sklearn.ensemble._forest.RandomForestC...    0.991118   \n",
      "\n",
      "                                         best_params      auc  precision  \\\n",
      "0  {'classifier': RandomForestClassifier(max_samp...  0.97619   0.999548   \n",
      "\n",
      "   recall        f1  FP  FN    TP  TN  \\\n",
      "0     1.0  0.999774   4   0  8848  80   \n",
      "\n",
      "                                            grid_obj  \n",
      "0  GridSearchCV(cv=5,\\n             estimator=Pip...  \n",
      "model score: 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59/2840836754.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_train_reg.fillna(value=Y_train_reg.mean(), inplace=True)\n",
      "/tmp/ipykernel_59/2840836754.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_test_reg.fillna(value=Y_test_reg.mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE date test : 71.84963498680114\n",
      "R^2 pe date de anternament: 0.9246735147877707\n",
      "R^2 pe date de test: 0.9376223613404624\n",
      "n_years:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1018: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "                                      classifierName  best_score  \\\n",
      "0  <class 'sklearn.ensemble._forest.RandomForestC...    0.997986   \n",
      "\n",
      "                                         best_params       auc  precision  \\\n",
      "0  {'classifier': RandomForestClassifier(max_samp...  0.999854   0.999563   \n",
      "\n",
      "     recall        f1  FP  FN     TP     TN  \\\n",
      "0  0.999825  0.999694   5   2  11434  42916   \n",
      "\n",
      "                                            grid_obj  \n",
      "0  GridSearchCV(cv=5,\\n             estimator=Pip...  \n",
      "model score: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59/2840836754.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_train_reg.fillna(value=Y_train_reg.mean(), inplace=True)\n",
      "/tmp/ipykernel_59/2840836754.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_test_reg.fillna(value=Y_test_reg.mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE date test : 64.97582245515665\n",
      "R^2 pe date de anternament: 0.931689251507551\n",
      "R^2 pe date de test: 0.8700580160771878\n"
     ]
    }
   ],
   "source": [
    "for n_years in [1,2,3,4]:\n",
    "\n",
    "    print('n_years: ', n_years)\n",
    "    model_clasificare = antrenare_clasificare(df, numeric_features, categorical_features, target, n_years)\n",
    "    model_regresie = antrenare_regresie(df[cols].reset_index(), numeric_features_reg, categorical_features_reg, target_reg, n_years)\n",
    "\n",
    "    filename_cslf = 'clasificator_facturi_n_years' + str(n_years) + '.sav'\n",
    "    pickle.dump(model_clasificare, open(filename_cslf, 'wb'))\n",
    "    filename_reg = 'regresor_DaysToSettle_n_years' + str(n_years) + '.sav'\n",
    "    pickle.dump(model_regresie, open(filename_reg, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58b797aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[['c_invoice_id', 'ad_org_id', 'dateinvoiced', 'c_bpartner_id',\n",
    "       'c_bpartner_location_id', 'paymentrule', 'grandtotal', 'duedate','totalopenamt',\n",
    "        'dayslate','late']]\n",
    "df_atribute_atribute_cbpartner = df[['c_invoice_id', 'ad_org_id', 'dateinvoiced', 'c_bpartner_id',\n",
    "       'c_bpartner_location_id'] + features + [target, target_reg]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "305f5687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = derived_features + ['late','dayslate','totalopenamt', 'paymentrule', 'tendertype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f119b19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b0ba6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_profilat = df_test.merge( df_atribute_atribute_cbpartner, \n",
    "                        on = ['c_invoice_id', 'ad_org_id',  'c_bpartner_id', 'c_bpartner_location_id'],\n",
    "                       how = 'left',\n",
    "                                suffixes = [None,\"_y\"])\n",
    "\n",
    "# construire set atribute necesare rularii\n",
    "X = df_test_profilat [ features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38f15ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59/930390258.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predictie_paid'] = y_hat_clsf\n",
      "/tmp/ipykernel_59/930390258.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predictie_paid'] = y_hat_clsf\n",
      "/tmp/ipykernel_59/930390258.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predictie_DaysToSettle'] = y_hat_reg\n",
      "/tmp/ipykernel_59/930390258.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predictie_DaysToSettle'] = df_test[['predictie_DaysToSettle','predictie_paid']].apply(lambda x : None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_invoice_id</th>\n",
       "      <th>ad_org_id</th>\n",
       "      <th>dateinvoiced</th>\n",
       "      <th>c_bpartner_id</th>\n",
       "      <th>c_bpartner_location_id</th>\n",
       "      <th>paymentrule</th>\n",
       "      <th>grandtotal</th>\n",
       "      <th>duedate</th>\n",
       "      <th>totalopenamt</th>\n",
       "      <th>dayslate</th>\n",
       "      <th>late</th>\n",
       "      <th>predictie_paid</th>\n",
       "      <th>predictie_DaysToSettle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1704039</td>\n",
       "      <td>1012210</td>\n",
       "      <td>2016-11-16</td>\n",
       "      <td>2107292</td>\n",
       "      <td>1458806</td>\n",
       "      <td>P</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2016-11-16</td>\n",
       "      <td>70.00</td>\n",
       "      <td>1538.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1704041</td>\n",
       "      <td>1012210</td>\n",
       "      <td>2016-11-16</td>\n",
       "      <td>2107293</td>\n",
       "      <td>1458807</td>\n",
       "      <td>P</td>\n",
       "      <td>30.00</td>\n",
       "      <td>2016-11-16</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1538.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1852334</td>\n",
       "      <td>1012210</td>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>2188183</td>\n",
       "      <td>1543354</td>\n",
       "      <td>P</td>\n",
       "      <td>99.00</td>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>99.00</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1852335</td>\n",
       "      <td>1012210</td>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>2188184</td>\n",
       "      <td>1543355</td>\n",
       "      <td>P</td>\n",
       "      <td>90.00</td>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>90.00</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1848802</td>\n",
       "      <td>1012210</td>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>2186956</td>\n",
       "      <td>1542038</td>\n",
       "      <td>P</td>\n",
       "      <td>128.00</td>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>128.00</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243773</th>\n",
       "      <td>5821693_0</td>\n",
       "      <td>1006527</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>5968872</td>\n",
       "      <td>4136808</td>\n",
       "      <td>P</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243820</th>\n",
       "      <td>5892010_1</td>\n",
       "      <td>1002402</td>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>2174995</td>\n",
       "      <td>1526817</td>\n",
       "      <td>P</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243829</th>\n",
       "      <td>5911474_0</td>\n",
       "      <td>1006527</td>\n",
       "      <td>2022-04-14</td>\n",
       "      <td>6076175</td>\n",
       "      <td>4296957</td>\n",
       "      <td>P</td>\n",
       "      <td>792.74</td>\n",
       "      <td>2022-04-24</td>\n",
       "      <td>792.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243872</th>\n",
       "      <td>5973559_0</td>\n",
       "      <td>1006527</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>5889823</td>\n",
       "      <td>4065636</td>\n",
       "      <td>P</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2022-05-18</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243890</th>\n",
       "      <td>5996647_0</td>\n",
       "      <td>1006527</td>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>6253584</td>\n",
       "      <td>4396972</td>\n",
       "      <td>P</td>\n",
       "      <td>12021.30</td>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>12021.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108560 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       c_invoice_id  ad_org_id dateinvoiced  c_bpartner_id  \\\n",
       "0           1704039    1012210   2016-11-16        2107292   \n",
       "1           1704041    1012210   2016-11-16        2107293   \n",
       "2           1852334    1012210   2017-04-06        2188183   \n",
       "3           1852335    1012210   2017-04-06        2188184   \n",
       "4           1848802    1012210   2017-04-03        2186956   \n",
       "...             ...        ...          ...            ...   \n",
       "243773    5821693_0    1006527   2022-03-21        5968872   \n",
       "243820    5892010_1    1002402   2022-04-11        2174995   \n",
       "243829    5911474_0    1006527   2022-04-14        6076175   \n",
       "243872    5973559_0    1006527   2022-05-03        5889823   \n",
       "243890    5996647_0    1006527   2022-05-11        6253584   \n",
       "\n",
       "        c_bpartner_location_id paymentrule  grandtotal    duedate  \\\n",
       "0                      1458806           P       70.00 2016-11-16   \n",
       "1                      1458807           P       30.00 2016-11-16   \n",
       "2                      1543354           P       99.00 2017-04-06   \n",
       "3                      1543355           P       90.00 2017-04-06   \n",
       "4                      1542038           P      128.00 2017-04-03   \n",
       "...                        ...         ...         ...        ...   \n",
       "243773                 4136808           P        0.01 2022-03-31   \n",
       "243820                 1526817           P        0.80 2022-05-11   \n",
       "243829                 4296957           P      792.74 2022-04-24   \n",
       "243872                 4065636           P        0.07 2022-05-18   \n",
       "243890                 4396972           P    12021.30 2022-05-26   \n",
       "\n",
       "        totalopenamt  dayslate  late  predictie_paid  predictie_DaysToSettle  \n",
       "0              70.00    1538.0   1.0             0.0                     NaN  \n",
       "1              30.00    1538.0   1.0             0.0                     NaN  \n",
       "2              99.00    1397.0   1.0             0.0                     NaN  \n",
       "3              90.00    1397.0   1.0             0.0                     NaN  \n",
       "4             128.00    1400.0   1.0             0.0                     NaN  \n",
       "...              ...       ...   ...             ...                     ...  \n",
       "243773          0.01       0.0   0.0             0.0                     NaN  \n",
       "243820          0.80       0.0   0.0             0.0                     NaN  \n",
       "243829        792.74       0.0   0.0             0.0                     NaN  \n",
       "243872          0.07       0.0   0.0             0.0                     NaN  \n",
       "243890      12021.30       0.0   0.0             0.0                     NaN  \n",
       "\n",
       "[108560 rows x 13 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_cslf = 'clasificator_facturi_n_years1.sav'\n",
    "\n",
    "#pipeline_clsf = Pipeline(steps = [])\n",
    "pipeline_clsf = pickle.load(open(filename_cslf, 'rb'))\n",
    "y_hat_clsf = pipeline_clsf[0].predict(X)\n",
    "df_test['predictie_paid'] = y_hat_clsf\n",
    "\n",
    "filename_reg = 'regresor_DaysToSettle_n_years4.sav'\n",
    "\n",
    "#pipeline_reg = Pipeline(steps = [])\n",
    "pipeline_reg = pickle.load(open(filename_reg, 'rb'))\n",
    "\n",
    "y_hat_reg = pipeline_reg.predict(X)\n",
    "\n",
    "# salvare prognoze\n",
    "df_test['predictie_paid'] = y_hat_clsf\n",
    "df_test['predictie_DaysToSettle'] = y_hat_reg\n",
    "df_test['predictie_DaysToSettle'] = df_test[['predictie_DaysToSettle','predictie_paid']].apply(lambda x : None\n",
    "                                                                                               if x[1] == 0 else round(x[0],0),\n",
    "                                                                                              axis = 1)\n",
    "df_test[df_test.predictie_paid == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b70279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f18c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

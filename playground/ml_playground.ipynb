{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4105e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.9/site-packages (2.9.3)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0cb68d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.9/site-packages (0.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn) (3.0.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn) (1.20.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5820fa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.9/site-packages (0.0)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (from sklearn) (1.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.0.0)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.7.1)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.20.3)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3689e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import timedelta, datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8fa8271",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://dev_db_user:dev_db_pass@postgres_db:5432/dev_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "512fac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * FROM machine_learning.cleaned_aggregated_data WHERE AD_Client_ID = 1000298', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1acc14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ad_client_id</th>\n",
       "      <th>ad_org_id</th>\n",
       "      <th>dateinvoiced</th>\n",
       "      <th>c_bpartner_id</th>\n",
       "      <th>c_invoice_id</th>\n",
       "      <th>c_bpartner_location_id</th>\n",
       "      <th>paymentrule</th>\n",
       "      <th>grandtotal</th>\n",
       "      <th>duedate</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_late_paid</th>\n",
       "      <th>std_late_paid</th>\n",
       "      <th>max_unpaid</th>\n",
       "      <th>min_unpaid</th>\n",
       "      <th>avg_unpaid</th>\n",
       "      <th>std_unpaid</th>\n",
       "      <th>max_late_unpaid</th>\n",
       "      <th>min_late_unpaid</th>\n",
       "      <th>avg_late_unpaid</th>\n",
       "      <th>std_late_unpaid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>519690</td>\n",
       "      <td>1000298</td>\n",
       "      <td>1002402</td>\n",
       "      <td>2013-09-09</td>\n",
       "      <td>1044431</td>\n",
       "      <td>1172123</td>\n",
       "      <td>1042886</td>\n",
       "      <td>P</td>\n",
       "      <td>105.61</td>\n",
       "      <td>2013-09-09</td>\n",
       "      <td>...</td>\n",
       "      <td>105.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>519691</td>\n",
       "      <td>1000298</td>\n",
       "      <td>1002402</td>\n",
       "      <td>2013-09-09</td>\n",
       "      <td>1044423</td>\n",
       "      <td>1172126</td>\n",
       "      <td>1042878</td>\n",
       "      <td>P</td>\n",
       "      <td>53.80</td>\n",
       "      <td>2013-09-09</td>\n",
       "      <td>...</td>\n",
       "      <td>53.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536479</td>\n",
       "      <td>1000298</td>\n",
       "      <td>1002402</td>\n",
       "      <td>2015-04-09</td>\n",
       "      <td>1135360</td>\n",
       "      <td>1341749</td>\n",
       "      <td>1133009</td>\n",
       "      <td>P</td>\n",
       "      <td>44.89</td>\n",
       "      <td>2015-04-09</td>\n",
       "      <td>...</td>\n",
       "      <td>44.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>519692</td>\n",
       "      <td>1000298</td>\n",
       "      <td>1002402</td>\n",
       "      <td>2013-09-09</td>\n",
       "      <td>1044322</td>\n",
       "      <td>1172129</td>\n",
       "      <td>1042773</td>\n",
       "      <td>P</td>\n",
       "      <td>51.85</td>\n",
       "      <td>2013-09-09</td>\n",
       "      <td>...</td>\n",
       "      <td>90.85</td>\n",
       "      <td>55.154329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>624391</td>\n",
       "      <td>1000298</td>\n",
       "      <td>1015531</td>\n",
       "      <td>2015-05-20</td>\n",
       "      <td>1142434</td>\n",
       "      <td>1358235</td>\n",
       "      <td>1140423</td>\n",
       "      <td>P</td>\n",
       "      <td>174.00</td>\n",
       "      <td>2015-05-20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  ad_client_id  ad_org_id dateinvoiced  c_bpartner_id c_invoice_id  \\\n",
       "0  519690       1000298    1002402   2013-09-09        1044431      1172123   \n",
       "1  519691       1000298    1002402   2013-09-09        1044423      1172126   \n",
       "2  536479       1000298    1002402   2015-04-09        1135360      1341749   \n",
       "3  519692       1000298    1002402   2013-09-09        1044322      1172129   \n",
       "4  624391       1000298    1015531   2015-05-20        1142434      1358235   \n",
       "\n",
       "   c_bpartner_location_id paymentrule  grandtotal    duedate  ...  \\\n",
       "0                 1042886           P      105.61 2013-09-09  ...   \n",
       "1                 1042878           P       53.80 2013-09-09  ...   \n",
       "2                 1133009           P       44.89 2015-04-09  ...   \n",
       "3                 1042773           P       51.85 2013-09-09  ...   \n",
       "4                 1140423           P      174.00 2015-05-20  ...   \n",
       "\n",
       "   avg_late_paid  std_late_paid max_unpaid min_unpaid  avg_unpaid  std_unpaid  \\\n",
       "0         105.61            NaN        0.0        0.0         0.0         NaN   \n",
       "1          53.80            NaN        0.0        0.0         0.0         NaN   \n",
       "2          44.89            NaN        0.0        0.0         0.0         NaN   \n",
       "3          90.85      55.154329        0.0        0.0         0.0         0.0   \n",
       "4            NaN            NaN      174.0      174.0       174.0         NaN   \n",
       "\n",
       "   max_late_unpaid  min_late_unpaid  avg_late_unpaid  std_late_unpaid  \n",
       "0              0.0              0.0              0.0              NaN  \n",
       "1              0.0              0.0              0.0              NaN  \n",
       "2              0.0              0.0              0.0              NaN  \n",
       "3              0.0              0.0              0.0              0.0  \n",
       "4            174.0            174.0            174.0              NaN  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43826293",
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_features =['closed_late_invoices_no',\n",
    "                  'paid_late_percent',\n",
    "                  'paid_late_total',\n",
    "                  'paid_late_raport_percent',\n",
    "                  'avg_days_paid_late',\n",
    "                  'late_unpaid_invoices_no',\n",
    "                  'late_unpaid_invoices_percent',\n",
    "                  'unpaid_invoices_late_sum',\n",
    "                  'late_unpaid_invoices_sum_percent'\n",
    "               ] + [x + '_paid' for x in ['max', 'min', 'avg', 'std']] \\\n",
    "                 + [x + '_late_paid' for x in ['max', 'min', 'avg', 'std']] \\\n",
    "                 + [x + '_unpaid' for x in ['max', 'min', 'avg', 'std']] \\\n",
    "                 + [x + '_late_unpaid' for x in ['max', 'min', 'avg', 'std']]\n",
    "# numeric_features = [c for c in features if df[c].dtype!=object ]\n",
    "# categorical_features = [c for c in features if df[c].dtype==object]\n",
    "features = derived_features + ['late','dayslate','totalopenamt', 'paymentrule', 'tendertype']\n",
    "target = 'paid'\n",
    "\n",
    "numeric_features = [c for c in features if df[c].dtype!=object ]\n",
    "categorical_features = [c for c in features if df[c].dtype==object]\n",
    "\n",
    "target_reg = 'daystosettle'\n",
    "features_reg =[f for f in features if f not in [target, target_reg]]\n",
    "\n",
    "numeric_features_reg = [c for c in features_reg if df[c].dtype!=object]\n",
    "categorical_features_reg = [c for c in features_reg if df[c].dtype==object]\n",
    "cols = numeric_features_reg + categorical_features_reg +[target_reg, target, 'dateinvoiced']\n",
    "df[ ['c_invoice_id', 'ad_org_id', 'dateinvoiced', 'c_bpartner_id',\n",
    "       'c_bpartner_location_id'] + features + [target, target_reg]].drop_duplicates().to_csv('atribute_cbpartner.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f5a097b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ea563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore',sparse = False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97658909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_clasificare(n_years, df, features, target):\n",
    "# pentru clasificare\n",
    "    X_train = df[df['dateinvoiced'] <= df['dateinvoiced'].max() + timedelta(days = -365*n_years)][features]\n",
    "    y_train = df[df['dateinvoiced'] <= df['dateinvoiced'].max() + timedelta(days = -365*n_years)][target]\n",
    "\n",
    "    X_test = df[(df['dateinvoiced'] > df['dateinvoiced'].max() + timedelta(days = -365*n_years)) &\n",
    "               (df['dateinvoiced'] <= df['dateinvoiced'].max() + timedelta(days = -365*(n_years-1)))][features]\n",
    "    y_test = df[(df['dateinvoiced'] > df['dateinvoiced'].max() + timedelta(days = -365*n_years)) &\n",
    "               (df['dateinvoiced'] <= df['dateinvoiced'].max() + timedelta(days = -365*(n_years-1)))][target]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72d34928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_regresie(n_years, df, features_reg, target_reg):\n",
    "\n",
    "\n",
    "    X_train_reg = df[(df.paid==1) & \n",
    "                     (df['dateinvoiced'] <= df['dateinvoiced'].max() + timedelta(days = -365*n_years))][features_reg]\n",
    "    Y_train_reg = df[(df.paid==1) & \n",
    "                     (df['dateinvoiced'] <= df['dateinvoiced'].max() + timedelta(days = -365*n_years))][target_reg]\n",
    "\n",
    "    X_test_reg = df[(df.paid==1) & (df['dateinvoiced'] > df['dateinvoiced'].max() + timedelta(days = -365*n_years)) &\n",
    "               (df['dateinvoiced'] <= df['dateinvoiced'].max() + timedelta(days = -365*(n_years-1)))][features_reg]\n",
    "\n",
    "    Y_test_reg = df[(df.paid==1) & (df['dateinvoiced'] > df['dateinvoiced'].max() + timedelta(days = -365*n_years)) &\n",
    "               (df['dateinvoiced'] <= df['dateinvoiced'].max() + timedelta(days = -365*(n_years-1)))][target_reg]\n",
    "    X_train_reg.fillna(value=X_train_reg.mean(), inplace=True)\n",
    "    Y_train_reg.fillna(value=Y_train_reg.mean(), inplace=True)\n",
    "    X_test_reg.fillna(value=X_test_reg.mean(), inplace=True)\n",
    "    Y_test_reg.fillna(value=Y_test_reg.mean(), inplace=True)\n",
    "    return X_train_reg, Y_train_reg, X_test_reg, Y_test_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ed7e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def antrenare_clasificare(df, numeric_features, categorical_features, target, n_years):\n",
    " \n",
    "    X_train, y_train, X_test, y_test = split_clasificare(n_years, df, numeric_features + categorical_features, target)\n",
    "    # la stringul 'classifier' adaugam '__' si sufixul reprezentat de parametrul\n",
    "    param_grid = [\n",
    "\n",
    "       {'classifier' : [BalancedRandomForestClassifier()],\n",
    "        'classifier__n_estimators' : [10,100,500],\n",
    "        'classifier__max_samples' : [0.1, 0.2, 0.3]},\n",
    "       # mai multe modele de incercat aici: logistic regression, XGBoost, SVM\n",
    "    ]\n",
    "\n",
    "    # bucla pentru tunarea si evaluarea clasificatorilor. returnam metrici pe care le putem colecta intr-un dataframe\n",
    "    lista_rezultate = []\n",
    "    lista_obiecte_grid_search = []\n",
    "\n",
    "    for clf_dict in param_grid:\n",
    "\n",
    "        # pasului de preprocesare ii adaugam clasificatorul curent; nu putem adauga decat un singur evaluator in\n",
    "        # pipeline, la sfarsit; de aceea am recurs la bucla\n",
    "        clsf = Pipeline(steps=[        \n",
    "                               ( 'column_transformer', ColumnTransformer(\n",
    "                            transformers=[\n",
    "                                ('num', numeric_transformer, \n",
    "                                 [list(X_train.columns.values).index(e) for e in numeric_features]),\n",
    "                                ('cat', categorical_transformer, \n",
    "                                  [list(X_train.columns.values).index(e) for e in categorical_features])],\n",
    "                               remainder='passthrough')                                         \n",
    "\n",
    "                           ),\n",
    "                              ('classifier', clf_dict['classifier'][0])])\n",
    "\n",
    "        grid = GridSearchCV(clsf, [clf_dict], cv=5, scoring='accuracy', verbose=0, n_jobs=-1)\n",
    "\n",
    "        # antrenare si fit\n",
    "        grid.fit(X_train, y_train)   \n",
    "\n",
    "        # predictie cu cea mai buna configurare in functie de scoringul ales - in cazul de mai sus accuracy\n",
    "        y_pred = grid.predict(X_test)\n",
    "\n",
    "        # curba roc\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "\n",
    "        # matricea de confuzie\n",
    "        cfmtrx = metrics.confusion_matrix(y_test,y_pred)\n",
    "\n",
    "        # culegem rezultatele in dictionare cu aceleasi chei - cel mai usor de transformat\n",
    "        lista_rezultate.append({\n",
    "            'classifierName': type(clf_dict['classifier'][0]),\n",
    "            'best_score':grid.best_score_,\n",
    "            'best_params':grid.best_params_,\n",
    "            'auc':metrics.roc_auc_score(y_test,y_pred),\n",
    "            'precision':metrics.precision_score(y_test,y_pred),\n",
    "            'recall':metrics.recall_score(y_test,y_pred),\n",
    "            'f1':metrics.f1_score(y_test,y_pred),\n",
    "            'FP':cfmtrx[0,1],\n",
    "            'FN':cfmtrx[1,0],\n",
    "            'TP':cfmtrx[1,1],\n",
    "            'TN':cfmtrx[0,0],\n",
    "            'grid_obj':grid\n",
    "\n",
    "        })\n",
    "        print('Done with {0}'.format(type(clf_dict['classifier'][0])))\n",
    "\n",
    "    df_result = pd.DataFrame(lista_rezultate)\n",
    "    df_result = df_result.sort_values(by ='best_score', ascending = False)\n",
    "    print(df_result.head())\n",
    "    # cel mai bun model\n",
    "    clsf = df_result.sort_values(by ='best_score', ascending = False).grid_obj[0].best_estimator_\n",
    "    # testarea: \n",
    "    clsf.fit(X_train,y_train)\n",
    "    y_pred = clsf.predict(X_test)\n",
    "    print(\"model score: %.3f\" % clsf.score(X_test, y_test))\n",
    "    c = confusion_matrix(y_test,y_pred)\n",
    "    \n",
    "    return clsf, df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad25e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def antrenare_regresie(df, numeric_features_reg,categorical_features_reg, target_reg, n_years ):\n",
    "    \n",
    "    cols = [c for c in df if c in numeric_features_reg + categorical_features_reg +[target_reg]]\n",
    "    features_reg = numeric_features_reg + categorical_features_reg\n",
    "    \n",
    "    X_train_reg, y_train_reg, X_test_reg, y_test_reg = split_regresie(n_years, df, features_reg, target_reg)\n",
    "\n",
    "    # lasso are un CV propriu. fapt pentru care standardizarea se va face acolo si o scoatem din preprocesare\n",
    "    numeric_transformer2 = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=0))])\n",
    "    \n",
    "    categorical_transformer2 = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore',sparse = False))])\n",
    "    \n",
    "    datatrsfm = Pipeline(steps=[        \n",
    "                           ( 'column_transformer', ColumnTransformer(\n",
    "                        transformers=[\n",
    "                            ('num', numeric_transformer2, \n",
    "                             [list(df[cols].columns.values).index(e) for e in numeric_features_reg]),\n",
    "                            ('cat', categorical_transformer2, \n",
    "                              [list(df[cols].columns.values).index(e) for e in categorical_features_reg])],\n",
    "                           remainder='passthrough'\n",
    "                           )                                         \n",
    "\n",
    "                       )])\n",
    "\n",
    "    lambda_values = 10**np.linspace(10,-3,100)*0.5\n",
    "    X_train_reg_trf = datatrsfm.fit_transform(X_train_reg)\n",
    "\n",
    "    lassocv = LassoCV(alphas = lambda_values, cv = 10, max_iter = 100000, normalize = True)\n",
    "\n",
    "    # antrenare si fit\n",
    "    lassocv.fit(X_train_reg_trf, y_train_reg)   \n",
    "\n",
    "    #pas 5\n",
    "    lambda_optim = lassocv.alpha_\n",
    "\n",
    "    # pas 6: reantrenare pe toate datele de antrenament\n",
    "    lasso = Lasso(max_iter = 100000, normalize = True)\n",
    "    lasso.set_params(alpha=lambda_optim)\n",
    "    lasso.fit(X_train_reg_trf, y_train_reg)\n",
    "\n",
    "    # pas 7 - raportatea erorii\n",
    "\n",
    "    pipeline_reg = Pipeline(steps=[        \n",
    "                       ( 'column_transformer', ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        ('num', numeric_transformer, \n",
    "                         [list(df[cols].columns.values).index(e) for e in numeric_features_reg]),\n",
    "                        ('cat', categorical_transformer, \n",
    "                          [list(df[cols].columns.values).index(e) for e in categorical_features_reg])],\n",
    "                       remainder='passthrough') ),\n",
    "                     ('lasso',lasso)   \n",
    "\n",
    "                   ])\n",
    "\n",
    "    pipeline_reg.fit(X_train_reg, y_train_reg)\n",
    "    y_hat_train_reg = pipeline_reg.predict(X_train_reg)\n",
    "    y_hat_test_reg = pipeline_reg.predict(X_test_reg)\n",
    "\n",
    "\n",
    "    cv_alpha_test_error = mean_squared_error(y_train_reg, \n",
    "                                             y_hat_train_reg)\n",
    "\n",
    "    print(\"MSE date test :\", cv_alpha_test_error)\n",
    "\n",
    "    # score(X, y[, sample_weight]) - coeficientul de determinare R^2 all predictiei.\n",
    "    print(\"R^2 pe date de anternament: {0}\".format(pipeline_reg.score(X_train_reg,y_train_reg)))\n",
    "    print(\"R^2 pe date de test: {0}\".format(pipeline_reg.score(X_test_reg,y_test_reg)))\n",
    "    return pipeline_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5072abc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_years:  1\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:1016: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with <class 'imblearn.ensemble._forest.BalancedRandomForestClassifier'>\n",
      "                                      classifierName  best_score  \\\n",
      "0  <class 'imblearn.ensemble._forest.BalancedRand...    0.991545   \n",
      "\n",
      "                                         best_params       auc  precision  \\\n",
      "0  {'classifier': BalancedRandomForestClassifier(...  0.809524    0.99782   \n",
      "\n",
      "   recall        f1  FP  FN     TP  TN  \\\n",
      "0     1.0  0.998909  24   0  10986  39   \n",
      "\n",
      "                                            grid_obj  \n",
      "0  GridSearchCV(cv=5,\\n             estimator=Pip...  \n",
      "model score: 0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py:6392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE date test : 70.10388673761412\n",
      "R^2 pe date de anternament: 0.9226173117758341\n",
      "R^2 pe date de test: 0.8565673022856045\n",
      "n_years:  2\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:1016: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with <class 'imblearn.ensemble._forest.BalancedRandomForestClassifier'>\n",
      "                                      classifierName  best_score  \\\n",
      "0  <class 'imblearn.ensemble._forest.BalancedRand...    0.998786   \n",
      "\n",
      "                                         best_params       auc  precision  \\\n",
      "0  {'classifier': BalancedRandomForestClassifier(...  0.998934   0.997492   \n",
      "\n",
      "   recall        f1  FP  FN    TP     TN  \\\n",
      "0     1.0  0.998744  23   0  9148  10765   \n",
      "\n",
      "                                            grid_obj  \n",
      "0  GridSearchCV(cv=5,\\n             estimator=Pip...  \n",
      "model score: 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py:6392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE date test : 69.51459951918129\n",
      "R^2 pe date de anternament: 0.9277066389158298\n",
      "R^2 pe date de test: 0.7756836646406186\n",
      "n_years:  3\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:1016: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with <class 'imblearn.ensemble._forest.BalancedRandomForestClassifier'>\n",
      "                                      classifierName  best_score  \\\n",
      "0  <class 'imblearn.ensemble._forest.BalancedRand...    0.989742   \n",
      "\n",
      "                                         best_params       auc  precision  \\\n",
      "0  {'classifier': BalancedRandomForestClassifier(...  0.999967   0.999801   \n",
      "\n",
      "   recall        f1  FP  FN     TP     TN  \\\n",
      "0     1.0  0.999901   3   0  15075  45325   \n",
      "\n",
      "                                            grid_obj  \n",
      "0  GridSearchCV(cv=5,\\n             estimator=Pip...  \n",
      "model score: 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py:6392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE date test : 59.65126506000202\n",
      "R^2 pe date de anternament: 0.9333707620348911\n",
      "R^2 pe date de test: 0.9006904242789626\n",
      "n_years:  4\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:1016: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with <class 'imblearn.ensemble._forest.BalancedRandomForestClassifier'>\n",
      "                                      classifierName  best_score  \\\n",
      "0  <class 'imblearn.ensemble._forest.BalancedRand...    0.997402   \n",
      "\n",
      "                                         best_params  auc  precision  recall  \\\n",
      "0  {'classifier': BalancedRandomForestClassifier(...  1.0        1.0     1.0   \n",
      "\n",
      "    f1  FP  FN     TP     TN  \\\n",
      "0  1.0   0   0  19367  24499   \n",
      "\n",
      "                                            grid_obj  \n",
      "0  GridSearchCV(cv=5,\\n             estimator=Pip...  \n",
      "model score: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py:6392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE date test : 74.50165594275656\n",
      "R^2 pe date de anternament: 0.9172637765547187\n",
      "R^2 pe date de test: 0.9694114693569503\n"
     ]
    }
   ],
   "source": [
    "for n_years in [1,2,3,4]:\n",
    "\n",
    "    print('n_years: ', n_years)\n",
    "    model_clasificare = antrenare_clasificare(df, numeric_features, categorical_features, target, n_years)\n",
    "    model_regresie = antrenare_regresie(df[cols].reset_index(), numeric_features_reg, categorical_features_reg, target_reg, n_years)\n",
    "\n",
    "    filename_cslf = 'clasificator_facturi_n_years' + str(n_years) + '.sav'\n",
    "    pickle.dump(model_clasificare, open(filename_cslf, 'wb'))\n",
    "    filename_reg = 'regresor_DaysToSettle_n_years' + str(n_years) + '.sav'\n",
    "    pickle.dump(model_regresie, open(filename_reg, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58b797aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[['c_invoice_id', 'ad_org_id', 'dateinvoiced', 'c_bpartner_id',\n",
    "       'c_bpartner_location_id', 'paymentrule', 'grandtotal', 'duedate','totalopenamt',\n",
    "        'dayslate','late']]\n",
    "df_atribute_atribute_cbpartner = df[['c_invoice_id', 'ad_org_id', 'dateinvoiced', 'c_bpartner_id',\n",
    "       'c_bpartner_location_id'] + features + [target, target_reg]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "305f5687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = derived_features + ['late','dayslate','totalopenamt', 'paymentrule', 'tendertype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f119b19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b0ba6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_profilat = df_test.merge( df_atribute_atribute_cbpartner, \n",
    "                        on = ['c_invoice_id', 'ad_org_id',  'c_bpartner_id', 'c_bpartner_location_id'],\n",
    "                       how = 'left',\n",
    "                                suffixes = [None,\"_y\"])\n",
    "\n",
    "# construire set atribute necesare rularii\n",
    "X = df_test_profilat [ features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38f15ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34/930390258.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predictie_paid'] = y_hat_clsf\n",
      "/tmp/ipykernel_34/930390258.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predictie_paid'] = y_hat_clsf\n",
      "/tmp/ipykernel_34/930390258.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predictie_DaysToSettle'] = y_hat_reg\n",
      "/tmp/ipykernel_34/930390258.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predictie_DaysToSettle'] = df_test[['predictie_DaysToSettle','predictie_paid']].apply(lambda x : None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_invoice_id</th>\n",
       "      <th>ad_org_id</th>\n",
       "      <th>dateinvoiced</th>\n",
       "      <th>c_bpartner_id</th>\n",
       "      <th>c_bpartner_location_id</th>\n",
       "      <th>paymentrule</th>\n",
       "      <th>grandtotal</th>\n",
       "      <th>duedate</th>\n",
       "      <th>totalopenamt</th>\n",
       "      <th>dayslate</th>\n",
       "      <th>late</th>\n",
       "      <th>predictie_paid</th>\n",
       "      <th>predictie_DaysToSettle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1358235</td>\n",
       "      <td>1015531</td>\n",
       "      <td>2015-05-20</td>\n",
       "      <td>1142434</td>\n",
       "      <td>1140423</td>\n",
       "      <td>P</td>\n",
       "      <td>174.00</td>\n",
       "      <td>2015-05-20</td>\n",
       "      <td>174.00</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1378367</td>\n",
       "      <td>1015531</td>\n",
       "      <td>2015-07-13</td>\n",
       "      <td>1148845</td>\n",
       "      <td>1147010</td>\n",
       "      <td>P</td>\n",
       "      <td>210.00</td>\n",
       "      <td>2015-07-13</td>\n",
       "      <td>210.00</td>\n",
       "      <td>2030.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1378369</td>\n",
       "      <td>1015531</td>\n",
       "      <td>2015-07-13</td>\n",
       "      <td>1148850</td>\n",
       "      <td>1147015</td>\n",
       "      <td>P</td>\n",
       "      <td>210.00</td>\n",
       "      <td>2015-07-13</td>\n",
       "      <td>210.00</td>\n",
       "      <td>2030.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1378371</td>\n",
       "      <td>1015531</td>\n",
       "      <td>2015-07-13</td>\n",
       "      <td>1148855</td>\n",
       "      <td>1147020</td>\n",
       "      <td>P</td>\n",
       "      <td>210.00</td>\n",
       "      <td>2015-07-13</td>\n",
       "      <td>210.00</td>\n",
       "      <td>2030.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1377336</td>\n",
       "      <td>1012210</td>\n",
       "      <td>2015-07-08</td>\n",
       "      <td>1148727</td>\n",
       "      <td>1146737</td>\n",
       "      <td>P</td>\n",
       "      <td>94.00</td>\n",
       "      <td>2015-07-08</td>\n",
       "      <td>94.00</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217634</th>\n",
       "      <td>3357757_0</td>\n",
       "      <td>1002402</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>1043629</td>\n",
       "      <td>2517736</td>\n",
       "      <td>P</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>9.00</td>\n",
       "      <td>483.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217658</th>\n",
       "      <td>3411216_0</td>\n",
       "      <td>1002402</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>2276882</td>\n",
       "      <td>1633247</td>\n",
       "      <td>P</td>\n",
       "      <td>27.80</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>27.80</td>\n",
       "      <td>460.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217662</th>\n",
       "      <td>3415973_0</td>\n",
       "      <td>1002402</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>3957900</td>\n",
       "      <td>3279771</td>\n",
       "      <td>P</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>0.10</td>\n",
       "      <td>455.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217672</th>\n",
       "      <td>3420538_0</td>\n",
       "      <td>1002402</td>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>2276882</td>\n",
       "      <td>1633247</td>\n",
       "      <td>P</td>\n",
       "      <td>121.88</td>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>121.88</td>\n",
       "      <td>453.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218004</th>\n",
       "      <td>4349206_0</td>\n",
       "      <td>1006527</td>\n",
       "      <td>2020-12-14</td>\n",
       "      <td>5540419</td>\n",
       "      <td>3739178</td>\n",
       "      <td>P</td>\n",
       "      <td>2899.79</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>2899.79</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107614 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       c_invoice_id  ad_org_id dateinvoiced  c_bpartner_id  \\\n",
       "4           1358235    1015531   2015-05-20        1142434   \n",
       "8           1378367    1015531   2015-07-13        1148845   \n",
       "10          1378369    1015531   2015-07-13        1148850   \n",
       "11          1378371    1015531   2015-07-13        1148855   \n",
       "14          1377336    1012210   2015-07-08        1148727   \n",
       "...             ...        ...          ...            ...   \n",
       "217634    3357757_0    1002402   2019-10-07        1043629   \n",
       "217658    3411216_0    1002402   2019-10-30        2276882   \n",
       "217662    3415973_0    1002402   2019-11-04        3957900   \n",
       "217672    3420538_0    1002402   2019-11-06        2276882   \n",
       "218004    4349206_0    1006527   2020-12-14        5540419   \n",
       "\n",
       "        c_bpartner_location_id paymentrule  grandtotal    duedate  \\\n",
       "4                      1140423           P      174.00 2015-05-20   \n",
       "8                      1147010           P      210.00 2015-07-13   \n",
       "10                     1147015           P      210.00 2015-07-13   \n",
       "11                     1147020           P      210.00 2015-07-13   \n",
       "14                     1146737           P       94.00 2015-07-08   \n",
       "...                        ...         ...         ...        ...   \n",
       "217634                 2517736           P        9.00 2019-10-07   \n",
       "217658                 1633247           P       27.80 2019-10-30   \n",
       "217662                 3279771           P        0.10 2019-11-04   \n",
       "217672                 1633247           P      121.88 2019-11-06   \n",
       "218004                 3739178           P     2899.79 2020-12-29   \n",
       "\n",
       "        totalopenamt  dayslate  late  predictie_paid  predictie_DaysToSettle  \n",
       "4             174.00    2084.0   1.0             0.0                     NaN  \n",
       "8             210.00    2030.0   1.0             0.0                     NaN  \n",
       "10            210.00    2030.0   1.0             0.0                     NaN  \n",
       "11            210.00    2030.0   1.0             0.0                     NaN  \n",
       "14             94.00    2035.0   1.0             0.0                     NaN  \n",
       "...              ...       ...   ...             ...                     ...  \n",
       "217634          9.00     483.0   1.0             0.0                     NaN  \n",
       "217658         27.80     460.0   1.0             0.0                     NaN  \n",
       "217662          0.10     455.0   1.0             0.0                     NaN  \n",
       "217672        121.88     453.0   1.0             0.0                     NaN  \n",
       "218004       2899.79      34.0   1.0             0.0                     NaN  \n",
       "\n",
       "[107614 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_cslf = 'clasificator_facturi_n_years1.sav'\n",
    "\n",
    "#pipeline_clsf = Pipeline(steps = [])\n",
    "pipeline_clsf = pickle.load(open(filename_cslf, 'rb'))\n",
    "y_hat_clsf = pipeline_clsf[0].predict(X)\n",
    "df_test['predictie_paid'] = y_hat_clsf\n",
    "\n",
    "filename_reg = 'regresor_DaysToSettle_n_years4.sav'\n",
    "\n",
    "#pipeline_reg = Pipeline(steps = [])\n",
    "pipeline_reg = pickle.load(open(filename_reg, 'rb'))\n",
    "\n",
    "y_hat_reg = pipeline_reg.predict(X)\n",
    "\n",
    "# salvare prognoze\n",
    "df_test['predictie_paid'] = y_hat_clsf\n",
    "df_test['predictie_DaysToSettle'] = y_hat_reg\n",
    "df_test['predictie_DaysToSettle'] = df_test[['predictie_DaysToSettle','predictie_paid']].apply(lambda x : None\n",
    "                                                                                               if x[1] == 0 else round(x[0],0),\n",
    "                                                                                              axis = 1)\n",
    "df_test[df_test.predictie_paid == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b70279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f18c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
